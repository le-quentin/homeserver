---
- name: Setup k3s cluster (install k3s and helm on nodes)
  hosts: k3scontroller
  vars:
    k3s_become: true
  tasks:
    - name: Python dependencies for kubernetes modules
      block:
        - name: Copy requirements.txt
          ansible.builtin.copy:
            src: "resources/k3s_setup/requirements.txt"
            dest: "/tmp/requirements.txt"
            mode: "0600"
        - name: Install requirements
          ansible.builtin.pip:
            requirements: /tmp/requirements.txt

    - name: Check if k3s is installed
      ansible.builtin.command: k3s --version
      register: k3s_installed
      ignore_errors: true
      failed_when: false
      changed_when: false
    - name: Setup k3s_server
      when: k3s_installed.rc != 0
      block:
        - name: Disable SWAP since kubernetes can't work with swap enabled (1/2)
          become: true
          ansible.builtin.shell: |
            swapoff -a
          changed_when: true
        - name: Disable SWAP in fstab since kubernetes can't work with swap enabled (2/2)
          become: true
          ansible.builtin.replace:
            path: /etc/fstab
            regexp: "^([^#].*?\\sswap\\s+sw\\s+.*)$"
            replace: "# \\1"
        - name: Install k3s
          ansible.builtin.include_role:
            name: xanmanning.k3s
          vars:
            k3s_release_version: v1.31.3+k3s1
            # TODO set node-status-update-frequency to something like 5s here, cuz the 5 minutes timeout by default in k3s is a lil long in a non HA setup
            k3s_server:
              node-name: controller-vm
              node-label:
                - "high-io-storage=true"

              cluster-cidr: "{{ k3s_cluster_cidr }}"
              service-cidr: "{{ k3s_services_cidr }}"
              cluster-dns: "{{ k3s_cluster_dns }}"
              write-kubeconfig-mode: "{{ k3s_write_kubeconfig_mode | default('0600') }}"
              debug: "{{ k3s_debug | default(false) }}"
    - name: Ensure kube folder exists
      ansible.builtin.file:
        path: "{{ home_dir }}/.kube"
        state: directory
        mode: "0744"
    - name: Copy k3s config for user
      become: true
      ansible.builtin.copy:
        src: /etc/rancher/k3s/k3s.yaml
        remote_src: true
        dest: "{{ home_dir }}/.kube/config"
        owner: "{{ ansible_user }}"
        mode: "0600"
        force: false

    - name: Install helm
      ansible.builtin.include_role:
        name: geerlingguy.helm
      vars:
        helm_version: v3.16.3
        helm_platform: linux
        helm_arch: "{{ ansible_architecture_alt }}"

#    - name: Setup NFS access
#      block:
#        - name: "Install nfs-common package"
#          become: true
#          ansible.builtin.package:
#            name: nfs-common
#        - name: "Create the csi-driver-nfs namespace"
#          kubernetes.core.k8s:
#            kind: Namespace
#            api_version: v1
#            name: csi-driver-nfs
#        - name: "Add the csi-driver-nfs helm repo"
#          kubernetes.core.helm_repository:
#            name: csi-driver-nfs
#            repo_url: "https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts"
#        - name: "Install csi-driver-nfs via helm"
#          kubernetes.core.helm:
#            name: csi-driver-nfs
#            chart_ref: csi-driver-nfs/csi-driver-nfs
#            chart_version: 4.9.0
#            release_namespace: csi-driver-nfs
#            values:
#              controller:
#                defaultOnDeletePolicy: retain
#              externalSnapshotter:
#                enabled: true

    - name: Setup cert-manager
      block:
        - name: Add cert-manager helm repo
          kubernetes.core.helm_repository:
            name: jetstack
            repo_url: https://charts.jetstack.io

        - name: Create cert-manager namespace
          kubernetes.core.k8s:
            kind: Namespace
            api_version: v1
            name: cert-manager

        - name: Install cert-manager via helm
          kubernetes.core.helm:
            name: cert-manager
            chart_ref: jetstack/cert-manager
            release_namespace: cert-manager
            create_namespace: false
            values:
              installCRDs: true
          register: cert_manager_install

        - name: Wait for cert-manager webhook to be ready
          when: cert_manager_install.changed
          ansible.builtin.wait_for:
            timeout: 30

        - name: Create Let's Encrypt ClusterIssuer
          when: "{{ cert_manager_issuer_name is defined }}"
          kubernetes.core.k8s:
            state: present
            definition:
              apiVersion: cert-manager.io/v1
              kind: ClusterIssuer
              metadata:
                name: "{{ cert_manager_issuer_name }}"
              spec:
                acme:
                  server: "{{ cert_manager_server }}"
                  email: "{{ cert_manager_email }}"
                  privateKeySecretRef:
                    name: "{{ cert_manager_issuer_name }}"
                  solvers:
                    - http01:
                        ingress:
                          class: traefik

    - name: Setup Longhorn
      block:
        - name: Ensure required packages for Longhorn are installed
          become: true
          ansible.builtin.package:
            name:
              - bash
              - curl
              - grep
              - jq
              - gawk
              - util-linux  # This package includes lsblk and blkid
            state: present

        - name: Ensure open-iscsi is installed
          become: true
          ansible.builtin.package:
            name: open-iscsi
            state: present
        - name: Ensure iscsid service is running
          become: true
          ansible.builtin.service:
            name: iscsid
            state: started
            enabled: true
        - name: Enable mount propagation for /mnt
          become: true
          ansible.builtin.command: mount --bind /mnt /mnt

        - name: Make /mnt rshared
          become: true
          ansible.builtin.command: mount --make-rshared /mnt

        - name: "Create the longhorn namespace"
          kubernetes.core.k8s:
            kind: Namespace
            api_version: v1
            name: longhorn-system
        - name: "Add the longhorn helm repo"
          kubernetes.core.helm_repository:
            name: longhorn
            repo_url: https://charts.longhorn.io
        - name: "Install Longhorn via helm"
          kubernetes.core.helm:
            name: longhorn
            chart_ref: longhorn/longhorn
            chart_version: "1.8.1"
            release_namespace: longhorn-system
            create_namespace: true
        - name: external-snapshotter version
          ansible.builtin.set_fact:
            external_snapshotter_version: "v8.2.0"
        - name: Install CSI snapshot CRDs
          kubernetes.core.k8s:
            state: present
            src: "https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/{{ external_snapshotter_version }}/client/config/crd/{{ item }}.yaml"
          loop:
            - snapshot.storage.k8s.io_volumesnapshotclasses
            - snapshot.storage.k8s.io_volumesnapshotcontents
            - snapshot.storage.k8s.io_volumesnapshots
        - name: Install CSI snapshot controller components
          kubernetes.core.k8s:
            state: present
            src: "https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/{{ external_snapshotter_version }}/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml"
        - name: Deploy the snapshot-controller
          kubernetes.core.k8s:
            state: present
            src: "https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/{{ external_snapshotter_version }}/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml"
        - name: "Unset Longhorn backup target" # we use a fake target, and if enabled here Longhorn will poll it forever and not cleanup resources, which leads to frozen system...
          kubernetes.core.k8s:
            state: present
            definition:
              apiVersion: longhorn.io/v1beta2
              kind: BackupTarget
              metadata:
                name: default
                namespace: longhorn-system
              spec:
                credentialSecret:
                pollInterval: "0"
                backupTargetURL: ""

#        - name: Create namespace for MinIO
#          kubernetes.core.k8s:
#            api_version: v1
#            kind: Namespace
#            name: minio
#
#        - name: Add the MinIO helm repo
#          kubernetes.core.helm_repository:
#            name: minio-operator
#            repo_url: https://operator.min.io/
#
#        - name: Deploy MinIO Operator using Helm
#          kubernetes.core.helm:
#            name: minio
#            chart_ref: minio-operator/operator
#            release_namespace: minio
#            create_namespace: false
#            values:
#              operator:
#                replicas: 1 # TODO - fix this, I still get 2 replicas
#
#        - name: Wait for MinIO Operator to be ready
#          kubernetes.core.k8s_info:
#            api_version: apps/v1
#            kind: Deployment
#            namespace: minio
#            name: minio-operator
#          register: minio_operator_deploy
#          until: minio_operator_deploy.resources[0].status.readyReplicas >= 1
#          retries: 10
#          delay: 15
#
#        - name: Create MinIO credentials secret
#          kubernetes.core.k8s:
#            state: present
#            definition:
#              apiVersion: v1
#              kind: Secret
#              metadata:
#                name: minio-creds
#                namespace: minio
#              type: Opaque
#              data:
#              accesskey: "{{ 'minioadmin' | b64encode }}"
#              secretkey: "{{ 'minioadmin' | b64encode }}"
#
#        - name: Deploy MinIO Tenant (Single Node Example)
#          kubernetes.core.k8s:
#            state: present
#            definition:
#              apiVersion: minio.min.io/v2
#              kind: Tenant
#              metadata:
#                name: longhorn-backups
#                namespace: minio
#              spec:
#                image: minio/minio:RELEASE.2023-08-04T17-40-21Z
#                credsSecret:
#                  name: minio-creds
#                pools:
#                  - name: pool-0
#                    servers: 1
#                    volumesPerServer: 1
#                    volumeClaimTemplate:
#                      metadata:
#                        name: data
#                      spec:
#                        accessModes:
#                          - ReadWriteOnce
#                        resources:
#                          requests:
#                            storage: 10Gi
#                mountPath: /export
#                requestAutoCert: false
#
#        - name: Set Longhorn backup credential secret
#          kubernetes.core.k8s:
#            state: present
#            definition:
#              apiVersion: v1
#              kind: Secret
#              metadata:
#                name: longhorn-backup-secret
#                namespace: longhorn-system
#              type: Opaque
#              data:
#                AWS_ACCESS_KEY_ID: "{{ 'minioadmin' | b64encode }}"
#                AWS_SECRET_ACCESS_KEY: "{{ 'minioadmin' | b64encode }}"
